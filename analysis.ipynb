{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries for notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Example for Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: The Data Scientist's Dilemma\n",
      "\n",
      "Dr. Emma Taylor had always been fascinated by the power of data. As a data scientist at a prominent tech firm, she spent her days poring over numbers and algorithms, trying to make sense of the world around her. But as she delved deeper into her work, she began to realize that there was more to life than just numbers and codes.\n",
      "\n",
      "Emma's latest project involved analyzing the purchasing habits of a popular retail chain. She had been tasked with identifying patterns and trends in customer behavior, in order to help the company optimize their sales strategies. As she worked tirelessly through the data sets, Emma began to notice something strange.\n",
      "\n",
      "The customers who were buying the most expensive items were not necessarily the ones with the highest incomes. In fact, some of the biggest spenders were actually low-income individuals, who were willing to splurge on luxury items despite their limited budgets. Emma was intrigued by this phenomenon and decided to dig deeper.\n",
      "\n",
      "She spent hours poring over her data, trying to find patterns that could explain why these customers were behaving in such a way. And then it hit her - the key to understanding lay not in the data itself, but in the emotions and experiences of the customers. Emma realized that these individuals were buying the luxury items as a form of escapism, a way to temporarily forget about their financial struggles and feel like they were living a more affluent life.\n",
      "\n",
      "Emma's findings were met with both excitement and skepticism by her colleagues. Some saw it as a groundbreaking discovery, while others believed it was too simplistic an explanation. But Emma knew that she had uncovered something deeper and more profound than just numbers and codes. She had caught a glimpse of the human experience, and she knew that this was just the beginning of her journey as a data scientist.\n",
      "\n",
      "As she presented her findings to her colleagues, Emma couldn't help but feel a sense of pride and accomplishment. She had taken something seemingly mundane and discovered a hidden truth within it. And in doing so, she had not only advanced the field of data science, but also gained a deeper understanding of the people behind the numbers.\n",
      "\n",
      "From that day on, Emma approached her work with a newfound appreciation for the emotional and psychological aspects of data analysis. She knew that there was more to life than just crunching numbers, and she was determined to uncover the stories hidden within the data. As she continued to explore the world of data science, Emma realized that she had found her true calling - not just as a scientist, but as a storyteller, using data as the ultimate narrative tool.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model='llama2', messages=[\n",
    "    {\n",
    "        # Who is writing(?)\n",
    "        'role':'user',\n",
    "        # The query to the LLM\n",
    "        'content':'Please write a short story about a data scientist',\n",
    "    },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrating that Ollama2 can be used to pull specific details out of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Payer: John\n",
      "* Recipient: James\n",
      "* Amount: $50\n"
     ]
    }
   ],
   "source": [
    "sys_msg = 'Grab the payer, recipient, amount from any sentence you are given'\n",
    "\n",
    "response = ollama.chat(model='llama2', messages=[\n",
    "    {\n",
    "        'role':'system',\n",
    "        'content':sys_msg,\n",
    "    },\n",
    "    {\n",
    "        'role':'user',\n",
    "        'content':'John payed James $50'\n",
    "    }\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same example but the output can be formatted as JSON, and certain outputs can be massaged to fit a pattern (e.g. say \"weekly\" instead of \"Friday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{\n",
      "    \"payer\": \"John\",\n",
      "    \"recipient\": \"James\",\n",
      "    \"amount\": \"$50\",\n",
      "    \"frequency\": \"weekly\"\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "sys_msg = \"\"\"Grab the payer, recipient, amount from any sentence you are given,\n",
    "    and output it in the following JSON format:\n",
    "    {{\n",
    "        \"payer\":\"<name of payer>\",\n",
    "        \"recipient\":\"<name of recipient>\",\n",
    "        \"amount\":\"<amount in USD>\",\n",
    "        \"frequency\":\"<frequency of payment>\" # display as \"hourly\", \"daily\", \"weekly\", etc.\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(model='llama2', messages=[\n",
    "    {\n",
    "        'role':'system',\n",
    "        'content':sys_msg,\n",
    "    },\n",
    "    {\n",
    "        'role':'user',\n",
    "        'content':'John payed James $50 every Friday'\n",
    "    }\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "messages must be a list of Message or dict-like objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m      1\u001b[0m sys_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mGrab the payer, recipient, amount from any sentence you are given,\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m    and output it in the following JSON format:\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m{{\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m    }}\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJohn pays James $50 every friday\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSam receives $20 from chuck the first of each month\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe local pub receives payment from a patron each week\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m ]\n\u001b[1;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mllama2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43msys_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ollama\\_client.py:169\u001b[0m, in \u001b[0;36mClient.chat\u001b[1;34m(self, model, messages, stream, format, options, keep_alive)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages \u001b[38;5;129;01mor\u001b[39;00m []:\n\u001b[0;32m    168\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages must be a list of Message or dict-like objects\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    170\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (role \u001b[38;5;241m:=\u001b[39m message\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m role \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages must contain a role and it must be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: messages must be a list of Message or dict-like objects"
     ]
    }
   ],
   "source": [
    "sys_msg = \"\"\"Grab the payer, recipient, amount from any sentence you are given,\n",
    "    and output it in the following JSON format:\n",
    "    {{\n",
    "        \"payer\":\"<name of payer>\",\n",
    "        \"recipient\":\"<name of recipient>\",\n",
    "        \"amount\":\"<amount in USD>\",\n",
    "        \"frequency\":\"<frequency of payment>\" # display as \"hourly\", \"daily\", \"weekly\", etc.\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "inputs = [\n",
    "    'John pays James $50 every friday',\n",
    "    'Sam receives $20 from chuck the first of each month',\n",
    "    'The local pub receives payment from a patron each week'\n",
    "]\n",
    "\n",
    "system_mode = {\n",
    "    'role':'system',\n",
    "    'content':sys_msg,\n",
    "}\n",
    "\n",
    "msgs = deque()\n",
    "\n",
    "response = ollama.chat(model='llama2', messages=[\n",
    "    {\n",
    "        'role':'system',\n",
    "        'content':sys_msg,\n",
    "    },\n",
    "    [\n",
    "        {'role':'user','content':inputs[0]}]\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
