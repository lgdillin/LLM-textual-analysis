{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on the SEC filing titled **\"MGT CAPITAL INVESTMENTS, INC.\"** filed on date **2021-04-15**. \n",
    "\n",
    "The original data file can be found in this repository under:\n",
    "`./data/mgt_capital.json`\n",
    "\n",
    "In this notebook, for the sake of specificity, is focused on the section common among many SEC filings:\n",
    "\n",
    "*item 7: Managementâ€™s Discussion and Analysis of Financial Condition and Results of Operations*\n",
    "\n",
    "To simplify the code, item 7 is extracted from the page and stored in \n",
    "`sample_data/sec_filing1/sec1.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the libraries to initialize the model\n",
    "\n",
    "*make sure you pull the nomic text first*\n",
    "\n",
    "`ollama pull nomic-embed-text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# We use the nomic-embed-text from our Ollama embedding wrapper. \n",
    "# We also use our Ollama LLM wrapper to load in the Llama3 model.\n",
    "Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "Settings.llm = Ollama(model='llama3', request_timeout=360.0, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on a small historical paragraph about the battle of Yorktown during the American Revolutionary War"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./sample_data/history/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington moved his force of almost 8,000 men south to Virginia.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"How many soldiers did Washington move to Virginia?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving to the SEC filing regarding MGT Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from llama_index.core.node_parser import LangchainNodeParser\n",
    "\n",
    "# load the entire contents of the directory\n",
    "documents = SimpleDirectoryReader(\"./sample_data/sec_filing1/\").load_data()\n",
    "\n",
    "# Split the text into paragraphs (not sure why I have to do this twice)\n",
    "Settings.text_splitter = LangchainNodeParser(RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0\n",
    "))\n",
    "\n",
    "# Initialize the vector store index with the transformed text\n",
    "index2 = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    transformations=[\n",
    "        LangchainNodeParser(RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=0\n",
    "    ))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model for accuracy. \n",
    "\n",
    "If the answer below states *$450*, it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$450.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index2.as_query_engine()\n",
    "response = query_engine.query(\"what was the end of the year revenue for 2019?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to the below query should be *$1,440*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided data, our revenues for the year ended December 31, 2020 increased by $990, or 220%, to $1,440 as compared to $450 for the year ended December 31, 2019.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"what was the end of the year revenue for 2020?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer below should be similar to *6 acres in Lafayette, Georgia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 acres of land were purchased in Lafayette, Georgia.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How many acres of land were purchased in Georgia for the facility?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer below should be similar to:\n",
    "\n",
    "Accretion of debt discount of \\$5,605, partially offset by a gain on extinguishment of debt of \\$3,540, interest income of \\$10, a gain on sale of property and equipment of \\$599, and a change in the fair value of the liability associated with the termination of the management agreements of \\$176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-operating expense for the year ended December 31, 2019 consisted of accretion of debt discount of $5,605, partially offset by a gain on extinguishment of debt of $3,540, interest income of $10, a gain on sale of property and equipment of $599, and a change in the fair value of the liability associated with the termination of the management agreements of $176.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What were the non-operating expenses in 2019?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a persistent storage for the generated Vector Store Index, to save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2.storage_context.persist(persist_dir='./llamaindex/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "June 2019 was the date when an equity purchase agreement was entered into, which allowed for the issuance and sale of shares to an investor from time to time up to a certain amount.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# State the settings for the model (if not already done)\n",
    "Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "Settings.llm = Ollama(model='llama3', request_timeout=360.0, seed=42)\n",
    "\n",
    "# load from disk\n",
    "re_load = load_index_from_storage(StorageContext.from_defaults(persist_dir='./llamaindex/'))\n",
    "\n",
    "# Query (answer should be June 2019)\n",
    "query_engine = re_load.as_query_engine()\n",
    "response = query_engine.query(\"What dates did any equity purchase agreements occur on?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add another document to the store. This documen can also be found at `./data/nuance_comm.json`. We will be analyzing the same financial condition section of the SEC filing, item 7. The formatting and style of these papers varys, and this particular document has a lot more tables in it, which makes preprocessing and cleaning the data for the LLM difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, Settings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from llama_index.core.node_parser import LangchainNodeParser\n",
    "\n",
    "# change the variable name to be more relevant in this context\n",
    "vector_index = re_load \n",
    "\n",
    "new_docs = SimpleDirectoryReader(\"./sample_data/sec_filing2/\").load_data()\n",
    "\n",
    "splitter = LangchainNodeParser(RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0\n",
    "))\n",
    "Settings.text_splitter = splitter\n",
    "\n",
    "new_nodes = splitter.get_nodes_from_documents(new_docs)\n",
    "vector_index.insert_nodes(new_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the index with the new document. The answer should be $1,362.4 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$1,362.4 million.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vector_index.as_query_engine()\n",
    "response = query_engine.query(\"What was the revenue for the end of the year in 2021?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue we have with this index, is by simply pulling the financial conditions out of the documents. If we were querying documents where multiple SEC filings had revenues posted for the same dates, we would be unable to tell which revenue matched to which organization. \n",
    "\n",
    "When running the query below, the model struggles to provide an accurate answer because both SEC filings have data from 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided data, the total revenues for Fiscal Year 2020 were not explicitly stated. However, we can infer that the geographic split for Fiscal Year 2020 was 79% in the United States and 21% internationally, with a hosting and professional services revenue that is not specified. Additionally, maintenance and support revenue for Fiscal Year 2020 was $256.7 million.\n",
      "\n",
      "To answer your query about the end-of-year revenue for 2020, we can look at the maintenance and support revenue, as it provides a percentage of total revenues. According to the table, maintenance and support revenue for Fiscal Year 2020 was $256.7 million, which is equivalent to 20% of total revenues.\n",
      "\n",
      "Using this information, we can estimate that the end-of-year revenue for 2020 would be approximately $1.26 billion (assuming a total revenue of $6.3 billion, calculated by dividing $256.7 million by 20%).\n"
     ]
    }
   ],
   "source": [
    "query_engine = vector_index.as_query_engine()\n",
    "response = query_engine.query(\"What was the revenue for the end of the year in 2020?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will need to be improved to have additional context when asking questions about multiple organizations whom all have financial activity with similar topics and dates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
