{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RunnableSequence.invoke() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 48\u001b[0m\n\u001b[0;32m     41\u001b[0m prompt_template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     42\u001b[0m     query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhich libraries and model providers offer LLMs?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt_template \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: RunnableSequence.invoke() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "from collections import deque\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# format JSON helps it probably output text in a syntactically correct JSON\n",
    "llm = ChatOllama(model=\"sec_analyzer_llama2\")\n",
    "\n",
    "# input_text = \"James Madison owns 3,500 shares or 25 percent of the stock, and james dean owns 1,600 or 10 percent.\"\n",
    "\n",
    "sys_msg1 = \"\"\"\n",
    "Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"\n",
    "Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    template=sys_msg1\n",
    ")\n",
    "\n",
    "prompt_template.format(\n",
    "    query=\"Which libraries and model providers offer LLMs?\",\n",
    "    context=context\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "According to the context provided, the following libraries and model providers offer Large Language Models (LLMs):\n",
      "\n",
      "1. Hugging Face's `transformers` library\n",
      "2. OpenAI using the `openai` library\n",
      "3. Cohere using the `cohere` library.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "from collections import deque\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# format JSON helps it probably output text in a syntactically correct JSON\n",
    "llm = ChatOllama(model=\"sec_analyzer_llama2\")\n",
    "\n",
    "directive = \"\"\"\n",
    "Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"\n",
    "Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\"\"\"\n",
    "\n",
    "query = \"Which libraries and model providers offer LLMs?\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=directive),\n",
    "    HumanMessage(content=context),\n",
    "    HumanMessage(content=query)\n",
    "]\n",
    "\n",
    "chat_model_response = llm.invoke(messages)\n",
    "print(chat_model_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
